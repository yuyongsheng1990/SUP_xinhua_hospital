{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,average_precision_score,precision_recall_curve\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,roc_auc_score,accuracy_score\n",
    "\n",
    "import xgboost\n",
    "# XGBoost模型\n",
    "xgb_model=xgboost.XGBClassifier(max_depth=5,\n",
    "                        learning_rate=0.018,\n",
    "                        n_estimators=500,\n",
    "                        min_child_weight=0.6,\n",
    "                        eta=0.1,\n",
    "                        gamma=0.5,\n",
    "                        reg_lambda=5,\n",
    "                        subsample=0.8,\n",
    "                        colsample_bytree=0.6,\n",
    "                        nthread=4,\n",
    "                        scale_pos_weight=1,\n",
    "                        random_state=3)\n",
    "\n",
    "xgb_model.fit(tran_x_sm,tran_y_sm)\n",
    "xgb_predictions=xgb_model.predict(test_x)\n",
    "\n",
    "\n",
    "import lightgbm\n",
    "# LightGBM模型\n",
    "lgbm_model=lightgbm.LGBMClassifier(iterations=300, \n",
    "                                  max_depth=8,\n",
    "                                  min_child_weight=0.9,\n",
    "                                  gamma=0.5,\n",
    "                                   reg_lambda=5,\n",
    "                                  subsample=0.4,\n",
    "                                  learning_rate=0.2, \n",
    "                                  loss_function='CrossEntropy',\n",
    "                                  random_state=3)\n",
    "lgbm_model.fit(tran_x_sm,tran_y_sm)\n",
    "lgbm_predictions=lgbm_model.predict(test_x)\n",
    "\n",
    "\n",
    "import catboost\n",
    "# CatBoost模型\n",
    "cat_model=catboost.CatBoostClassifier(iterations=300, \n",
    "                                      learning_rate=0.2, \n",
    "                                      depth=6,\n",
    "                                      l2_leaf_reg=2,\n",
    "                                      subsample=1,\n",
    "                                      loss_function='CrossEntropy',\n",
    "                                      random_state=3)\n",
    "cat_model.fit(tran_x_sm,tran_y_sm)\n",
    "cat_predictions=cat_model.predict(test_x)\n",
    "\n",
    "\n",
    "# 随机森林\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# 列出参数列表\n",
    "tree_grid_parameter = {'n_estimators': list((10, 50, 100, 150, 200))}\n",
    "# 进行参数的搜索组合\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid=tree_grid_parameter, cv=3)\n",
    "# 根据已有数据去拟合随机森林模型\n",
    "grid.fit(tran_x_sm, tran_y_sm)\n",
    "rf_model = RandomForestClassifier(n_estimators=grid.best_params_['n_estimators'],\n",
    "                            max_depth=8,\n",
    "                            random_state=3)\n",
    "rf_model.fit(tran_x_sm, tran_y_sm)\n",
    "# 预测缺失值\n",
    "rf_predictions = rf_model.predict(test_x)\n",
    "\n",
    "\n",
    "# GBDT\n",
    "# 列出参数列表\n",
    "gbdt_model = GradientBoostingClassifier(n_estimators=300,\n",
    "                            learning_rate=0.1,\n",
    "                            max_depth=8,\n",
    "                            subsample=0.4,\n",
    "                            random_state=3)\n",
    "gbdt_model.fit(tran_x_sm,tran_y_sm)\n",
    "# 预测缺失值\n",
    "gbdt_predictions = gbdt_model.predict(test_x)\n",
    "\n",
    "\n",
    "# SVR\n",
    "from sklearn.svm import SVR,SVC\n",
    "# 回归模型\n",
    "# svr = SVR(kernel='linear', C=1.25)\n",
    "# 分类模型\n",
    "svr_model = SVC(kernel='rbf',\n",
    "          C=50,\n",
    "          cache_size=200,\n",
    "            probability=True,\n",
    "          random_state=3)\n",
    "svr_model.fit(tran_x_sm,tran_y_sm)\n",
    "svr_predictions=svr_model.predict(test_x)\n",
    "\n",
    "\n",
    "# Linear回归，Lasso回归，领回归，logistic回归\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge,ElasticNet,LogisticRegression\n",
    "lcv_model = LogisticRegression(penalty='l2',\n",
    "                         C=5,\n",
    "                        solver='lbfgs',\n",
    "                         max_iter=100,\n",
    "                        random_state=3)\n",
    "# lcv = Lasso()\n",
    "# lcv = Ridge()\n",
    "lcv_model.fit(tran_x_sm, tran_y_sm)\n",
    "lcv_predictions = lcv_model.predict(test_x)\n",
    "\n",
    "# ANN\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "ANN_model = MLPClassifier(alpha=0.1, \n",
    "                    hidden_layer_sizes=[100,], \n",
    "                    solver='adam', \n",
    "                    activation='relu', \n",
    "                    random_state=3)\n",
    "ANN_model.fit(tran_x_sm, tran_y_sm)\n",
    "ANN_predictions=ANN_model.predict(test_x)\n",
    "\n",
    "\n",
    "# TabNet\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "TabNet_model = TabNetClassifier(n_d=8, \n",
    "                               n_a=8,\n",
    "                               n_steps=3, # Number of steps in the architecture (usually between 3 and 10)\n",
    "                               gamma=1.5,\n",
    "                               n_independent=2)  #TabNetRegressor()\n",
    "tran_x_x, tran_x_valid, tran_y_y, tran_y_valid = train_test_split(tran_x_sm, tran_y_sm, test_size=0.125, random_state=3)\n",
    "\n",
    "TabNet_model.fit(X_train=tran_x_x.to_numpy(), \n",
    "        y_train=tran_y_y.to_numpy(), \n",
    "        eval_set=[(tran_x_valid.to_numpy(), tran_y_valid.to_numpy())], \n",
    "        eval_name=['train'], \n",
    "        eval_metric=['auc'],\n",
    "        max_epochs=200,\n",
    "        patience=50,\n",
    "        batch_size=128,\n",
    "        virtual_batch_size=14,\n",
    "        num_workers=0,\n",
    "        drop_last=False)\n",
    "\n",
    "TabNet_predictions=TabNet_model.predict(test_x.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统一模型输出结果\n",
    "df_model_result=pd.DataFrame(\n",
    "    columns=['model','index','precision','recall','f1-score','support','accuracy','AUC','sensitivity','specificity'])\n",
    "\n",
    "model_list=[xgb_model,lgbm_model,cat_model,rf_model,gbdt_model,svr_model,lcv_model,ANN_model,TabNet_model]\n",
    "model_name_list=['XGBoost','LGBM','CatBoost','RF','GBDT','SVR','LR','ANN','TabNet']\n",
    "for model,name in zip(model_list,model_name_list):\n",
    "#     print(name)\n",
    "    # 计算accuracy和AUC\n",
    "    if name == 'TabNet':\n",
    "        test_x=test_x.to_numpy()\n",
    "    test_y_score=model.predict_proba(test_x)[:,-1]\n",
    "    auc=roc_auc_score(test_y,test_y_score)\n",
    "    auc=round(auc,4)\n",
    "    accuracy=accuracy_score(test_y,model.predict(test_x))\n",
    "    accuracy=round(accuracy,4)\n",
    "    # 计算灵敏度sensitivity和特异度specificity\n",
    "    # 计算灵敏度、特异度\n",
    "    tn, fp, fn, tp = confusion_matrix(test_y,model.predict(test_x)).ravel()\n",
    "    sensitivity=round(tp/(tp+fn),4)\n",
    "    specificity=round(tn/(fp+tn),4)\n",
    "    df_model_result.loc[df_model_result.shape[0],['model','accuracy','AUC','sensitivity','specificity']]=\\\n",
    "                                                              [name,accuracy,auc,sensitivity,specificity]\n",
    "    # 并入二分类的P-R-f1\n",
    "    # 提取classification_report结果\n",
    "    report = classification_report(test_y, model.predict(test_x), output_dict=True)  # output_dict转化为字典类型\n",
    "    df_report = pd.DataFrame(report).transpose()  # 转置\n",
    "    df_report=df_report.apply(lambda x: round(x,4),axis=0)\n",
    "    df_report=df_report.reset_index(drop=True)\n",
    "    df_model_result=pd.concat([df_model_result,df_report.loc[0:1,:].reset_index()],axis=0)\n",
    "    df_model_result=df_model_result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_result.rename(columns={'model':'',\n",
    "                               'index':'label'},inplace=True)\n",
    "# 保存模型测试效果\n",
    "df_model_result.to_excel(project_path+'/data/df_模型测试效果.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,average_precision_score,precision_recall_curve\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,roc_auc_score,accuracy_score\n",
    "\n",
    "import xgboost\n",
    "# XGBoost模型\n",
    "xgb_model=xgboost.XGBRegressor(max_depth=5,\n",
    "                        learning_rate=0.018,\n",
    "                        n_estimators=500,\n",
    "                        min_child_weight=0.6,\n",
    "                        eta=0.1,\n",
    "                        gamma=0.5,\n",
    "                        reg_lambda=5,\n",
    "                        subsample=0.8,\n",
    "                        colsample_bytree=0.6,\n",
    "                        nthread=4,\n",
    "                        scale_pos_weight=1,\n",
    "                        random_state=3)\n",
    "\n",
    "xgb_model.fit(tran_x,tran_y)\n",
    "xgb_predictions=xgb_model.predict(test_x)\n",
    "\n",
    "\n",
    "import lightgbm\n",
    "# LightGBM模型\n",
    "lgbm_model=lightgbm.LGBMRegressor(iterations=300, \n",
    "                                  max_depth=8,\n",
    "                                  min_child_weight=0.9,\n",
    "                                  gamma=0.5,\n",
    "                                   reg_lambda=5,\n",
    "                                  subsample=0.4,\n",
    "                                  learning_rate=0.2, \n",
    "                                  loss_function='MAE',\n",
    "                                  random_state=3)\n",
    "lgbm_model.fit(tran_x,tran_y)\n",
    "lgbm_predictions=lgbm_model.predict(test_x)\n",
    "\n",
    "import catboost\n",
    "# CatBoost模型\n",
    "cat_model=catboost.CatBoostRegressor(iterations=300, \n",
    "                                      learning_rate=0.2, \n",
    "                                      depth=6,\n",
    "                                      l2_leaf_reg=2,\n",
    "                                      subsample=1,\n",
    "                                      loss_function='MAE',\n",
    "                                      random_state=3)\n",
    "cat_model.fit(tran_x,tran_y)\n",
    "cat_predictions=cat_model.predict(test_x)\n",
    "\n",
    "# 随机森林\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# 列出参数列表\n",
    "tree_grid_parameter = {'n_estimators': list((10, 50, 100, 150, 200))}\n",
    "# 进行参数的搜索组合\n",
    "grid = GridSearchCV(RandomForestRegressor(), param_grid=tree_grid_parameter, cv=3)\n",
    "# 根据已有数据去拟合随机森林模型\n",
    "grid.fit(tran_x, tran_y)\n",
    "rf_model = RandomForestRegressor(n_estimators=grid.best_params_['n_estimators'],\n",
    "                            max_depth=8,\n",
    "                            random_state=3)\n",
    "rf_model.fit(tran_x, tran_y)\n",
    "# 预测缺失值\n",
    "rf_predictions = rf_model.predict(test_x)\n",
    "\n",
    "# GBDT\n",
    "# 列出参数列表\n",
    "gbdt_model = GradientBoostingRegressor(n_estimators=300,\n",
    "                            learning_rate=0.1,\n",
    "                            max_depth=8,\n",
    "                            subsample=0.4,\n",
    "                            random_state=3)\n",
    "gbdt_model.fit(tran_x,tran_y)\n",
    "# 预测缺失值\n",
    "gbdt_predictions = gbdt_model.predict(test_x)\n",
    "\n",
    "# SVR\n",
    "from sklearn.svm import SVR,SVC\n",
    "# 回归模型\n",
    "# svr = SVR(kernel='linear', C=1.25)\n",
    "# 分类模型\n",
    "svr_model = SVR()\n",
    "svr_model.fit(tran_x,tran_y)\n",
    "svr_predictions=svr_model.predict(test_x)\n",
    "\n",
    "\n",
    "# Linear回归，Lasso回归，领回归，logistic回归\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge,ElasticNet,LogisticRegression\n",
    "# lcv_model = LogisticRegression()\n",
    "lcv_model = Lasso()\n",
    "# lcv = Ridge()\n",
    "lcv_model.fit(tran_x, tran_y)\n",
    "lcv_predictions = lcv_model.predict(test_x)\n",
    "\n",
    "\n",
    "# ANN\n",
    "from sklearn.neural_network import MLPClassifier,MLPRegressor\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "ANN_model = MLPRegressor(alpha=0.1, \n",
    "                    hidden_layer_sizes=[100,], \n",
    "                    solver='adam', \n",
    "                    activation='relu', \n",
    "                    random_state=3)\n",
    "ANN_model.fit(tran_x, tran_y)\n",
    "ANN_predictions=ANN_model.predict(test_x)\n",
    "\n",
    "# TabNet\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "TabNet_model = TabNetRegressor(n_d=8, \n",
    "                               n_a=8,\n",
    "                               n_steps=3, # Number of steps in the architecture (usually between 3 and 10)\n",
    "                               gamma=1.5,\n",
    "                               n_independent=2)  #TabNetRegressor()\n",
    "tran_x_x, tran_x_valid, tran_y_y, tran_y_valid = train_test_split(tran_x, tran_y, test_size=0.125, random_state=3)\n",
    "\n",
    "TabNet_model.fit(X_train=tran_x_x.to_numpy(), \n",
    "        y_train=tran_y_y.to_numpy().reshape(-1,1), \n",
    "        eval_set=[(tran_x_valid.to_numpy(), tran_y_valid.to_numpy().reshape(-1,1))], \n",
    "        eval_name=['train'], \n",
    "        eval_metric=['mae'],\n",
    "        max_epochs=200,\n",
    "        patience=50,\n",
    "        batch_size=128,\n",
    "        virtual_batch_size=14,\n",
    "        num_workers=0,\n",
    "        drop_last=False)\n",
    "\n",
    "TabNet_predictions=TabNet_model.predict(test_x.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error\n",
    "# 统一模型结果\n",
    "df_model_result=pd.DataFrame(\n",
    "    columns=['model','R2','RMSE','MAE','Accuracy within ± 10% range','Accuracy within ± 20% range','Accuracy within ± 30% range',\n",
    "             'Accuracy within ± 40% range'])\n",
    "model_list=[xgb_model,lgbm_model,cat_model,rf_model,gbdt_model,svr_model,lcv_model,ANN_model,TabNet_model]\n",
    "model_name_list=['XGBoost','LGBM','CatBoost','RF','GBDT','SVR','LR','ANN','TabNet']\n",
    "for model,name in zip(model_list,model_name_list):\n",
    "#     print(name)\n",
    "    # 计算R2、RMSE、MAE\n",
    "    if name == 'TabNet':\n",
    "        predictions=model.predict(test_x.to_numpy())\n",
    "    else:\n",
    "        predictions=model.predict(test_x)\n",
    "    r2=r2_score(test_y,predictions)\n",
    "    r2=round(r2,4)\n",
    "    mae=mean_absolute_error(test_y,predictions)\n",
    "    mae=round(mae,4)\n",
    "    rmse=mean_squared_error(test_y,predictions) ** 0.5\n",
    "    rmse=round(rmse,4)\n",
    "\n",
    "    # 计算'Accuracy within ± 10%, 20%, 30%, 40% range'\n",
    "    accuracy_10_list = [ (i,j) for i,j in zip(test_y,predictions) if abs((i-j)/i)<=0.1]\n",
    "    accuracy_10_perc = round(len(accuracy_10_list)/len(test_y),4)\n",
    "    accuracy_10_perc=\"%.2f%%\" % (accuracy_10_perc * 100)      # 百分数输出\n",
    "\n",
    "    accuracy_20_list = [ (i,j) for i,j in zip(test_y,predictions) if abs((i-j)/i)<=0.2]\n",
    "    accuracy_20_perc = round(len(accuracy_20_list)/len(test_y),4)\n",
    "    accuracy_20_perc=\"%.2f%%\" % (accuracy_20_perc * 100)      # 百分数输出\n",
    "    \n",
    "    accuracy_30_list = [ (i,j) for i,j in zip(test_y,predictions) if abs((i-j)/i)<=0.3]\n",
    "    accuracy_30_perc = round(len(accuracy_30_list)/len(test_y),4)\n",
    "    accuracy_30_perc=\"%.2f%%\" % (accuracy_30_perc * 100)      # 百分数输出\n",
    "    \n",
    "    accuracy_40_list = [ (i,j) for i,j in zip(test_y,predictions) if abs((i-j)/i)<=0.4]\n",
    "    accuracy_40_perc = round(len(accuracy_40_list)/len(test_y),4)\n",
    "    accuracy_40_perc=\"%.2f%%\" % (accuracy_40_perc * 100)      # 百分数输出\n",
    "    \n",
    "    df_model_result.loc[df_model_result.shape[0],['model','R2','RMSE','MAE','Accuracy within ± 10% range', \n",
    "                                                  'Accuracy within ± 20% range','Accuracy within ± 30% range',\n",
    "                                                 'Accuracy within ± 40% range']]=\\\n",
    "                                                  [name,r2,rmse,mae,accuracy_10_perc,accuracy_20_perc,accuracy_30_perc,\n",
    "                                                  accuracy_40_perc]\n",
    "    df_model_result=df_model_result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_result.rename(columns={'model':''},inplace=True)\n",
    "# 保存模型测试效果\n",
    "df_model_result.to_excel(project_path+'/data/df_模型测试效果.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "460.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
